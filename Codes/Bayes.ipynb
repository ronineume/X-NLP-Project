{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4f50fc-ba16-41f2-bc6d-3e40313c7dfa",
   "metadata": {},
   "source": [
    "# Text Classification System (Naive Bayes classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5d05f-46a6-45da-a04f-1babb40da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "df = pd.read_csv('cleanprocessed_sampled_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7709f5c-7d71-4add-a6e4-5caef02c2189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_emoji(text):\n",
    "    return emoji.replace_emoji(text, replace=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29003e15-f705-4123-b4a2-c62fda1bc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to lowercase and replace non-alphanumeric characters and the word 'url' with a space\n",
    "df[\"text\"] = df[\"text\"].str.lower().str.replace(\"([^0-9A-Za-z \\t])|\\burl\\b\", \" \", case=False, regex=True)\n",
    "\n",
    "# Drop duplicate entries based on the 'text' column\n",
    "df = df.drop_duplicates(\"text\")\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    t = row[\"text\"]  # Get the original text\n",
    "    cleaned_text = strip_emoji(t)  # Remove emojis\n",
    "    # Update the processed text back to the original 'text' column\n",
    "    df.at[index, \"text\"] = cleaned_text\n",
    "\n",
    "# Print the number of unique reviews\n",
    "print(df.shape[0])  # Number of unique reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322a129d-d76d-4427-bddd-514709acab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "# Plot the distribution\n",
    "class_names = ['Trump', 'Harris', 'Others']\n",
    "ax = sns.countplot(x=df.VoteWho)\n",
    "plt.xlabel('tweet support')\n",
    "ax.set_xticklabels(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae5013-de6e-4c3b-bf56-b2723d0a8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VoteWho'] = df['VoteWho'].replace({\n",
    "    1: 'Trump',\n",
    "    2: 'Harris',\n",
    "    3: 'Others'\n",
    "})\n",
    "RANDOM_SEED = 42\n",
    "df_train, df_test = train_test_split(df[['text','VoteWho']], test_size=0.2, random_state=RANDOM_SEED)\n",
    "df_train.to_csv('train_support.csv', index=False, header=False, encoding='utf-8-sig')\n",
    "df_test.to_csv('test_support.csv', index=False, header=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293f78a-d876-425a-b028-59109c6daef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "# reading the train csv and train the classifier\n",
    "with open('train_support.csv', 'r', encoding='utf-8-sig') as f:\n",
    "  cl = NaiveBayesClassifier(f, format='csv')\n",
    "\n",
    "# test the accuracy of the classifier on the test csv\n",
    "with open('test_support.csv', 'r', encoding='utf-8-sig') as f:\n",
    "  print(cl.accuracy(f, format='csv'))\n",
    "\n",
    "# classify a text using the classifier\n",
    "text = \"I feel like I am missing something here.\"\n",
    "\n",
    "print(cl.classify(text))\n",
    "# prints physics\n",
    "\n",
    "# check the informative features\n",
    "print(cl.show_informative_features(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e346a-e88c-41bb-b3b4-8c505539ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data to be classified\n",
    "processed_cleaned_data = pd.read_csv('processed_cleaned_data.csv')\n",
    "\n",
    "# Define a function for classification\n",
    "def classify_text(text):\n",
    "    return cl.classify(text)\n",
    "\n",
    "# Classify each row in the 'text' column and store the results in the 'support' column\n",
    "processed_cleaned_data['support'] = processed_cleaned_data['text'].apply(classify_text)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "processed_cleaned_data.to_csv('classified_data_bayes.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Classification completed and saved as 'classified_data_bayes.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
