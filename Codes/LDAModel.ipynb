{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60404301-b777-45a5-8984-48aba82a1877",
   "metadata": {},
   "source": [
    "# Topic Modeling (Gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a4c892-b134-4ca8-8a82-95e51e471d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast  # Used to convert strings to lists\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv(\"normalized_data.csv\")\n",
    "\n",
    "# Extract the 'normalization' column and convert it to list format\n",
    "texts = [ast.literal_eval(row) for row in df['normalization']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b4a3c-62b2-44a2-b6d0-33214bda2583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dictionary and convert the documents \n",
    "texts_dictionary = corpora.Dictionary(texts)\n",
    "# to bag of words (bow) representation using the dictionary\n",
    "texts_corpus = [texts_dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# train the model\n",
    "# the more iteration, the more stable the model\n",
    "# Set training parameters.\n",
    "num_topics = 20\n",
    "chunksize = 3000\n",
    "passes = 10\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "np.random.seed(432)\n",
    "\n",
    "topics_model = LdaModel(\n",
    "    texts_corpus,\n",
    "    id2word = texts_dictionary,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61457fa-1f5c-43d1-bb42-3d7f3b377bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the topic distribution for each document\n",
    "corpus_lda = topics_model[texts_corpus]  # Use the trained LDA model\n",
    "thetas = [topics_model[c] for c in texts_corpus]  # Retrieve the topic distribution for each document\n",
    "\n",
    "# Calculate the number of topics per document (considering only topics with probability greater than 0.06)\n",
    "hist_data = [len([topic for topic in t if topic[1] > 0.06]) for t in thetas]\n",
    "\n",
    "# Plot a histogram of topic counts\n",
    "counts, bins = np.histogram(hist_data, bins=np.arange(1, num_topics + 2) - 0.5)\n",
    "\n",
    "# Use rainbow colors for the bars\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(counts)))\n",
    "\n",
    "for x in range(len(counts)):\n",
    "    plt.bar(x + 1, counts[x], color=colors[x], edgecolor='black', width=0.8)\n",
    "\n",
    "plt.xlabel('Number of Topics per Tweet')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.title('Distribution of Topic Counts per Tweet')\n",
    "plt.xticks(range(1, num_topics + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc80aa-425d-4ef6-b936-e0570bc117d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c001ce-2a89-407f-b9d4-6a85d34d0545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel# spaCy for preprocessing\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', topics_model.log_perplexity(texts_corpus))  \n",
    "# a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=topics_model, texts=texts, dictionary=texts_dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5623f7-0fe1-4173-94ec-1add07ecc418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# Visualize topics\n",
    "pyLDAvis.enable_notebook() \n",
    "vis = pyLDAvis.gensim.prepare(topics_model, texts_corpus, texts_dictionary) \n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
