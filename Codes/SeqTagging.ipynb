{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610e930b-77cd-46d7-a69d-0ed9b0c44941",
   "metadata": {},
   "source": [
    "# Sequential tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f379e-85ba-4574-8a9e-a8b378aa2180",
   "metadata": {},
   "source": [
    "## Part-of-speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96701f38-c109-4dd7-a32f-6f8525e0e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv(\"processed_cleaned_data.csv\")\n",
    "\n",
    "# Define a function for POS tagging\n",
    "def pos_tag_text(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.tags  # Return the POS tagging results\n",
    "\n",
    "# Apply the function to each row of text and create a new column 'pos_tags'\n",
    "df['pos_tags'] = df['text'].apply(pos_tag_text)\n",
    "\n",
    "# Expand the pos_tags column into separate rows\n",
    "pos_df = df.explode('pos_tags')\n",
    "\n",
    "# Split into two new columns: word and tag\n",
    "pos_df[['word', 'tag']] = pos_df['pos_tags'].apply(pd.Series)\n",
    "\n",
    "# Count duplicates and add to a new column 'number'\n",
    "pos_df['number'] = pos_df.groupby(['word', 'tag'])['word'].transform('count')\n",
    "\n",
    "# Select the required columns\n",
    "final_df = pos_df[['word', 'tag', 'number']].drop_duplicates()\n",
    "\n",
    "# Print the first few rows to confirm\n",
    "print(final_df.head())\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file = \"pos_tagged_result.csv\"\n",
    "final_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Tokenization completed and saved to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773932f5-21b0-4d50-9632-ad0e18953502",
   "metadata": {},
   "source": [
    "## Shallow Parsing (Chunking) SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175d5e1-dadc-43a0-a577-b01b501680d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv(\"processed_cleaned_data.csv\")\n",
    "texts = df['text']\n",
    "\n",
    "# Randomly sample 10 texts\n",
    "sampled_texts = texts.sample(n=10, random_state=5)  # Set random_state for reproducibility\n",
    "\n",
    "# Perform dependency parsing and visualization for each sampled text\n",
    "for text in sampled_texts:\n",
    "    doc = nlp(text)\n",
    "    print(f\"Processing text: {text}\\n\")\n",
    "    \n",
    "    # Print dependency information for each token\n",
    "    for token in doc:\n",
    "        print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "              [child.text for child in token.children])\n",
    "    \n",
    "    # Visualize dependency parsing\n",
    "    displacy.render(doc, style=\"dep\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator for different text outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b24796f-16c1-4cb0-924b-87d2ed650980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Perform dependency parsing and visualization for each sampled text\n",
    "# Define output directory\n",
    "output_dir = Path(\"images\")  # Ensure the output directory exists\n",
    "\n",
    "# Create directory (if it does not exist)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for i, text in enumerate(sampled_texts):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Visualize dependency parsing and generate SVG\n",
    "    svg = displacy.render(doc, style=\"dep\", jupyter=False)\n",
    "\n",
    "    # Generate file name, removing punctuation\n",
    "    file_name = '-' + f\"_{i}.svg\"  # Add index to avoid name collisions\n",
    "    output_path = output_dir / file_name  # Use Path object to concatenate paths\n",
    "\n",
    "    # Save the SVG file\n",
    "    with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(svg)  # Write the SVG content to the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a65e33-d968-4880-85bb-432c493274ae",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6e88f-cddf-49fd-a37b-5650c71345fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv(\"processed_cleaned_data.csv\")\n",
    "texts = df['text']\n",
    "\n",
    "# Randomly sample 20 texts\n",
    "sampled_texts = texts.sample(n=20, random_state=3)  # Set random_state for reproducibility\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# Iterate over each sampled text and perform named entity recognition and visualization\n",
    "for text in sampled_texts:\n",
    "    doc = nlp(text)\n",
    "    # Use displacy for visualization\n",
    "    displacy.render(doc, style=\"ent\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator for different text outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13749cf0-947a-4eb4-90a7-c47c29c8169c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
