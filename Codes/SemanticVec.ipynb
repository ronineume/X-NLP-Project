{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb83cc32-56ef-4579-b939-63bb2615ea3e",
   "metadata": {},
   "source": [
    "# Word2Vector (Gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0bd2e-5e94-45b6-b905-ccc01fe64122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import ast  # Used to convert strings to lists\n",
    "\n",
    "# Read the CSV file containing normalized data\n",
    "df = pd.read_csv('normalized_data.csv')\n",
    "\n",
    "# Convert each row's string into a list\n",
    "corpus = df['normalization'].apply(ast.literal_eval).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca47a1-9eab-4f5c-b105-3d49ec0dbbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus, compute_loss=True, vector_size=250, workers =10, min_count = 5, window=5)\n",
    "training_loss = model.get_latest_training_loss()\n",
    "print(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde6597e-3d25-4ef8-a8c7-fe24fd1869eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word vectors\n",
    "king_vector = model.wv['creat']\n",
    "man_vector = model.wv['financi']\n",
    "# queen_vector = model.wv['harri']  # Uncomment if needed\n",
    "woman_vector = model.wv['decis']\n",
    "\n",
    "# Calculate vector relationship\n",
    "vector_relation = king_vector - man_vector + woman_vector\n",
    "\n",
    "# Find the closest words to the calculated vector\n",
    "similar_words = model.wv.similar_by_vector(vector_relation, topn=5)\n",
    "\n",
    "# Output results\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baff0ec-9747-445a-b5fc-9805ce0fc65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(w2v_model, words, topn=20):\n",
    "    similar_df = pd.DataFrame()\n",
    "    for word in words:\n",
    "        try:\n",
    "            similar_words = pd.DataFrame(w2v_model.wv.most_similar(word, topn=topn), columns=[word, 'cos'])\n",
    "            similar_df = pd.concat([similar_df, similar_words], axis=1)\n",
    "        except:\n",
    "            print(word, \"not found in Word2Vec model!\")\n",
    "    return similar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a336d44-83d2-4252-b93c-29c549ade194",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(model, ['trump','harri','elect','presid','maga','tweet','cycl','ground','head','strategi','us'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792e172-d237-4290-a7a0-75cf71b80f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Define a list of keywords for clustering\n",
    "keys = ['trump', 'elect', 'presid', 'maga', 'cycl', 'ground', 'head', 'strategi', 'us', 'misinform', 'result', 'news']\n",
    "\n",
    "embedding_clusters = []\n",
    "word_clusters = []\n",
    "\n",
    "# Iterate through each key word\n",
    "for word in keys:\n",
    "    embeddings = []\n",
    "    words = []\n",
    "    # Get the most similar words for each key word\n",
    "    for similar_word, _ in model.wv.most_similar(word, topn=30):\n",
    "        words.append(similar_word)\n",
    "        embeddings.append(model.wv[similar_word])\n",
    "    embedding_clusters.append(embeddings)\n",
    "    word_clusters.append(words)\n",
    "    \n",
    "# Extract word vectors\n",
    "embedding_clusters = np.array(embedding_clusters)\n",
    "\n",
    "# Perform t-SNE dimensionality reduction\n",
    "n, m, k = embedding_clusters.shape  # n is the number of key words, k is the embedding dimension\n",
    "tsne_model_en_2d = TSNE(perplexity=15, n_components=2, init='pca', n_iter=3500, random_state=32)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c80d67-b06a-4310-b010-56d92a5641dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "embedding_clusters = np.array(embedding_clusters)\n",
    "n, m, k = embedding_clusters.shape\n",
    "tsne_model_en_2d = TSNE(perplexity=15, n_components=2, init='pca', n_iter=3500, random_state=32)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80467cbe-baba-4d7e-b905-6b389a9c7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def tsne_plot_similar_words(title, labels, embedding_clusters, word_clusters, a, filename=None):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
    "    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n",
    "        x = embeddings[:, 0]\n",
    "        y = embeddings[:, 1]\n",
    "        plt.scatter(x, y, c=color, alpha=a, label=label)\n",
    "        for i, word in enumerate(words):\n",
    "            plt.annotate(word, alpha=0.5, xy=(x[i], y[i]), xytext=(5, 2),\n",
    "                         textcoords='offset points', ha='right', va='bottom', size=8)\n",
    "    plt.legend(loc=4)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    if filename:\n",
    "        plt.savefig(filename, format='png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "tsne_plot_similar_words('Similar words from tweets', keys, embeddings_en_2d, word_clusters, 0.7,\n",
    "                        'similar_words.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f84bc-2608-4fa3-a774-08925aaa53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, word in enumerate(model.wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(model.wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356855bb-7ff7-48b3-a955-81e2e99e1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(\"trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb87de00-beb2-4e91-8fb4-68bb448bf8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "\n",
    "# Initialize lists for words and their embeddings\n",
    "words_ak = []\n",
    "embeddings_ak = []\n",
    "\n",
    "# Iterate through the vocabulary using key_to_index\n",
    "for word in list(model.wv.key_to_index):  # Use key_to_index to get the vocabulary\n",
    "    embeddings_ak.append(model.wv[word])  # Get the word vector\n",
    "    words_ak.append(word)\n",
    "\n",
    "# Convert embeddings_ak to a NumPy array\n",
    "embeddings_ak = np.array(embeddings_ak)\n",
    "\n",
    "# Perform t-SNE for dimensionality reduction\n",
    "tsne_ak_2d = TSNE(perplexity=30, n_components=2, init='pca', n_iter=3500, random_state=32)\n",
    "embeddings_ak_2d = tsne_ak_2d.fit_transform(embeddings_ak)  \n",
    "\n",
    "# Define a function to plot the t-SNE results\n",
    "def tsne_plot_2d(label, embeddings, words=[], a=1):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, 1))\n",
    "    x = embeddings[:, 0]\n",
    "    y = embeddings[:, 1]\n",
    "    plt.scatter(x, y, c=colors, alpha=a, label=label)\n",
    "\n",
    "    # Randomly select 50 indices for labeling\n",
    "    selected_indices = random.sample(range(len(words)), 50)\n",
    "    for i in selected_indices:\n",
    "        plt.annotate(words[i], alpha=0.7, xy=(x[i], y[i]), xytext=(10, 4), \n",
    "                     textcoords='offset points', ha='right', va='bottom', size=12)\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"hhh.png\", format='png', dpi=450, bbox_inches='tight')  # Save the plot as an image\n",
    "    plt.show()  # Display the plot\n",
    "\n",
    "# Call the plotting function for all key words\n",
    "tsne_plot_2d('All key words', embeddings_ak_2d, words_ak, a=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e60ac1-6d3f-433c-a26d-9e7490988da9",
   "metadata": {},
   "source": [
    "## K Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80fae1-3658-4d0f-a6b8-a9a5b522e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Import pandas library for data processing and DataFrame operations\n",
    "import numpy as np  # Import NumPy library for numerical computations\n",
    "from sklearn.cluster import KMeans  # Import KMeans from sklearn for clustering analysis\n",
    "\n",
    "def word_cluster(wv, n_clusters=80):\n",
    "    \"\"\"\n",
    "    Perform KMeans clustering on the given word vector model and save the results to an Excel file.\n",
    "\n",
    "    Parameters:\n",
    "    wv -- Word vector model (Word2Vec or similar model)\n",
    "    n_clusters -- Number of clusters to form (default is 80)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the L2 norm (magnitude) of each word vector and reshape it to (-1, 1)\n",
    "    uv = np.linalg.norm(wv.vectors, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    # Normalize the word vectors\n",
    "    wv.vectors = wv.vectors / uv\n",
    "\n",
    "    # Perform KMeans clustering and get the labels for each word\n",
    "    labels = KMeans(n_clusters).fit(wv.vectors).labels_\n",
    "\n",
    "    # Create a DataFrame combining words and their corresponding cluster labels\n",
    "    df = pd.DataFrame([(w, labels[e]) for e, w in enumerate(wv.index_to_key)], columns=['word', 'label'])\n",
    "    \n",
    "    # Sort the DataFrame by cluster labels\n",
    "    df.sort_values(by='label', inplace=True)\n",
    "    \n",
    "    # Save the results to an Excel file without using the encoding parameter\n",
    "    df.to_excel('word_cluster_.xlsx', index=False)\n",
    "\n",
    "# Call the function to perform word clustering\n",
    "word_cluster(model.wv)  # model.wv is a trained word vector model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
